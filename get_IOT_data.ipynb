{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first section only have exploratory trials..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This function will use CKAN api to get packages list plus the url for the resources under each entity \n",
    "## The results are stored in a pandas DF\n",
    "\n",
    "import pprint\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def getPackageList(url_api):\n",
    "    r = requests.get(url_api)\n",
    "    j = r.json()\n",
    "    return(pd.DataFrame({\"package_id\": j['result']}))\n",
    "\n",
    "def getResourceUrl(package_id):\n",
    "    url = \"https://opendata.porto.hackacity.eu\" + \"/api/3/action/package_show?id=\" + package_id;  \n",
    "    r = requests.get(url)\n",
    "    j = r.json()\n",
    "    return(j['result']['resources'][0]['url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Usage\n",
    "\n",
    "url_api = \"https://opendata.porto.hackacity.eu/api/3/action/package_list\"\n",
    "df = getPackageList(url_api)\n",
    "\n",
    "df[\"resource_url\"] = list(map(getResourceUrl, df[\"package_id\"]))\n",
    "\n",
    "#print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get packageIds as a list\n",
    "\n",
    "def getPackageIds(url):\n",
    "    r = requests.get(url)\n",
    "    j = r.json()\n",
    "    return(j['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Usage\n",
    "\n",
    "url = \"https://opendata.porto.hackacity.eu/api/3/action/package_list\";\n",
    "packageIdsList = getPackageIds(url)\n",
    "#print(packageIdsList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For a list of packagesIds extract the available metadata and store the results in a pandas DF\n",
    "\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "def normalizeJSON(url, package_id):\n",
    "    url = url + package_id;  \n",
    "    r = requests.get(url)\n",
    "    j = r.json()\n",
    "    return(json_normalize(j['result']))\n",
    "\n",
    "def appendRowToDF(df1, df2):\n",
    "    df = pd.DataFrame()\n",
    "    if df1.empty: \n",
    "        df = df1.copy()\n",
    "    else:\n",
    "        df = pd.concat([df1,df2])\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Usage\n",
    "\n",
    "packagesMetadata = pd.DataFrame()\n",
    "url = \"https://opendata.porto.hackacity.eu/api/3/action/package_show?id=\"\n",
    "for packageId in packageIdsList:\n",
    "    row = normalizeJSON(url, packageId)\n",
    "    packagesMetadata = appendRowToDF(packagesMetadata, row)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Request live data and store the result in a panda DF\n",
    "\n",
    "import requests\n",
    "import pprint\n",
    "import pandas\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "def getLiveData(api_url, package_id = None, device_id = None):\n",
    "    if (package_id is None) and (device_id is not None):\n",
    "        url = api_url + \"/v2/entities?id=\" + device_id\n",
    "    elif (package_id is not None) and (device_id is None):\n",
    "        url = api_url + \"/v2/entities?type=\" + package_id\n",
    "    else:\n",
    "        raise Exception(\"package_id or device_id required or are simultaneous defined!\")\n",
    "\n",
    "    print(url)\n",
    "    \n",
    "    r = requests.get(url)\n",
    "    j = r.json()\n",
    "    #pprint.pprint(j)\n",
    "    return(json_normalize(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example with error\n",
    "#api_url = \"https://broker.fiware.urbanplatform.portodigital.pt\"\n",
    "#df = getLiveData(api_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://broker.fiware.urbanplatform.portodigital.pt/v2/entities?type=AirQualityObserved\n"
     ]
    }
   ],
   "source": [
    "## Example without device id\n",
    "api_url = \"https://broker.fiware.urbanplatform.portodigital.pt\"\n",
    "package_id = \"AirQualityObserved\"\n",
    "df = getLiveData(api_url, package_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://broker.fiware.urbanplatform.portodigital.pt/v2/entities?id=urn:ngsi-ld:AirQualityObserved:porto:environment:ubiwhere:5adf39366f555a4514e7ea54\n"
     ]
    }
   ],
   "source": [
    "## Example with device id\n",
    "api_url = \"https://broker.fiware.urbanplatform.portodigital.pt\"\n",
    "device_id = \"urn:ngsi-ld:AirQualityObserved:porto:environment:ubiwhere:5adf39366f555a4514e7ea54\"\n",
    "df = getLiveData(api_url, device_id = device_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example \n",
    "## require getHistoricalData function declared below!!!\n",
    "\n",
    "#resource_list = ['urn:ngsi-ld:AirQualityObserved:porto:environment:ubiwhere:5adf39366f555a4514e7ea54', \n",
    "#                 'urn:ngsi-ld:AirQualityObserved:porto:environment:ubiwhere:5b97a1bde521e3053085c08c', \n",
    "#                 'urn:ngsi-ld:AirQualityObserved:porto:environment:ubiwhere:5b632f2706599b05e998bed8',\n",
    "#                 'urn:ngsi-ld:AirQualityObserved:porto:environment:ubiwhere:5b72dbfa06599b05e9a74f27',\n",
    "#                 'urn:ngsi-ld:AirQualityObserved:porto:environment:ubiwhere:5b97a1a6e521e3053085c067']\n",
    "\n",
    "#api_url = \"http://history-data.urbanplatform.portodigital.pt\"\n",
    "\n",
    "#df = pd.DataFrame()\n",
    "#for resource in resource_list:\n",
    "#    print(resource)\n",
    "#    df1 = getHistoricalData(api_url, device_id = resource, no=500)\n",
    "#    #print(df1.columns)\n",
    "#    if df.empty:\n",
    "#        df = df1.copy()\n",
    "#    else:\n",
    "#        df = pd.concat([df,df1])\n",
    "#    #print(df.columns)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "From this point forward are the sequential steps to get the IOT data...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## List IOT entities\n",
    "import requests\n",
    "import json\n",
    "\n",
    "def getListIOTEntities(api_url):\n",
    "    url = api_url + \"/v2/types\"\n",
    "    r = requests.get(url)\n",
    "    j = r.json()\n",
    "    entity_list = []\n",
    "    for item in j:\n",
    "        #print(item['type'])\n",
    "        entity_list.append(item['type'])\n",
    "    return(entity_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AirQualityObserved', 'ArrivalEstimation', 'Device', 'Event', 'GtfsTransitFeedFile', 'NoiseLevelObserved', 'OffStreetParking', 'PointOfInterest', 'TrafficFlowObserved', 'Vehicle', 'WeatherForecast', 'WeatherObserved', 'gtfsAgency', 'gtfsCalendarDateRule', 'gtfsCalendarRule', 'gtfsRoute', 'gtfsService', 'gtfsStop']\n"
     ]
    }
   ],
   "source": [
    "api_url = \"https://broker.fiware.urbanplatform.portodigital.pt\"\n",
    "entity_list = getListIOTEntities(api_url)\n",
    "print(entity_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reduce entity_list to the ones of interest (MANUAL STEP)\n",
    "entity_list = ['AirQualityObserved']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get list of all available resources/devices for an entity\n",
    "\n",
    "import requests\n",
    "import pprint\n",
    "\n",
    "def getResourceList(api_url, entity_name):\n",
    "    # First let's the ID's from the FiWare\n",
    "    url = api_url + \"/v2/entities?type=\" + entity_name\n",
    "    #print(url)\n",
    "    r = requests.get(url, verify=False)\n",
    "    j = r.json()\n",
    "    #print(j)\n",
    "    resources_list = []\n",
    "    for resource in j: \n",
    "      resources_list.append(resource['id'])\n",
    "    return(resources_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cha1av/dev/hackacity/env/lib/python3.5/site-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    }
   ],
   "source": [
    "api_url = \"https://broker.fiware.urbanplatform.portodigital.pt\"\n",
    "\n",
    "resource_list = []\n",
    "for entity in entity_list:\n",
    "    #print(entity)\n",
    "    resource_list.append(getResourceList(api_url, entity))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(resource_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flat resource_list\n",
    "resource_list_flat = [item for sublist in resource_list for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove stuff that is giving errors\n",
    "#resource_list_flat.remove('Trindade_1_Rotacao')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['urn:ngsi-ld:AirQualityObserved:porto:environment:ubiwhere:5adf39366f555a4514e7ea54', 'urn:ngsi-ld:AirQualityObserved:porto:environment:ubiwhere:5b97a1bde521e3053085c08c', 'urn:ngsi-ld:AirQualityObserved:porto:environment:ubiwhere:5b632f2706599b05e998bed8', 'urn:ngsi-ld:AirQualityObserved:porto:environment:ubiwhere:5b72dbfa06599b05e9a74f27', 'urn:ngsi-ld:AirQualityObserved:porto:environment:ubiwhere:5b97a1a6e521e3053085c067']\n"
     ]
    }
   ],
   "source": [
    "print(resource_list_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Request historical data with resource_id and store the results as a panda DF for a single device\n",
    "\n",
    "import requests\n",
    "import pprint\n",
    "import pandas\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "def convertJSONHistoricalToDF(j):\n",
    "    df = pd.DataFrame()\n",
    "    for i in range(0,len(j['data']['attributes'])):\n",
    "        df[j['data']['attributes'][i]['attrName']] = j['data']['attributes'][i]['values']\n",
    "    ## expand location attributes\n",
    "    #for key in df['location'][0].keys():\n",
    "    #    df[key] = str(df['location'][0][key])\n",
    "    df['long'] = df['location'][0]['coordinates'][0]\n",
    "    df['lat'] = df['location'][0]['coordinates'][1]\n",
    "    df['device_id'] = j['data']['entityId']\n",
    "    #print(df)\n",
    "    return(df)\n",
    "    \n",
    "def getHistoricalData(api_url, device_id = None, no = 20):\n",
    "    if (device_id is not None):\n",
    "        url = api_url + \"/v2/entities/\" + device_id + \"?limit=\" + str(no)\n",
    "    else:\n",
    "        raise Exception(\"device_id is required\")\n",
    "\n",
    "    #print(url)\n",
    "    r = requests.get(url)\n",
    "    j = r.json()\n",
    "    #json_normalize(j['data'], record_path=['attributes']).transpose()\n",
    "    return(convertJSONHistoricalToDF(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "urn:ngsi-ld:AirQualityObserved:porto:environment:ubiwhere:5adf39366f555a4514e7ea54\n",
      "urn:ngsi-ld:AirQualityObserved:porto:environment:ubiwhere:5b97a1bde521e3053085c08c\n",
      "urn:ngsi-ld:AirQualityObserved:porto:environment:ubiwhere:5b632f2706599b05e998bed8\n",
      "urn:ngsi-ld:AirQualityObserved:porto:environment:ubiwhere:5b72dbfa06599b05e9a74f27\n",
      "urn:ngsi-ld:AirQualityObserved:porto:environment:ubiwhere:5b97a1a6e521e3053085c067\n"
     ]
    }
   ],
   "source": [
    "api_url = \"http://history-data.urbanplatform.portodigital.pt\"\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for resource in resource_list_flat:\n",
    "    print(resource)\n",
    "    df1 = getHistoricalData(api_url, device_id = resource, no=500)\n",
    "    #print(df1.columns)\n",
    "    if df.empty:\n",
    "        df = df1.copy()\n",
    "    else:\n",
    "        df = pd.concat([df,df1], sort=False)\n",
    "    #print(df.columns)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pprint.pprint(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DF operations\n",
    "\n",
    "import  time\n",
    "import datetime\n",
    "\n",
    "# Convert timestamp to unixtime\n",
    "def convert_df_to_unix(s):\n",
    "    time_mask = \"%Y-%m-%dT%H:%M:%S.%f\"\n",
    "    return(time.mktime(datetime.datetime.strptime(s, time_mask).timetuple()))\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['time'] = list(map(convert_df_to_unix, df['dateObserved']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./output/IOT_AirQuality_CO.csv\n",
      "./output/IOT_AirQuality_NO2.csv\n",
      "./output/IOT_AirQuality_O3.csv\n",
      "./output/IOT_AirQuality_Ox.csv\n",
      "./output/IOT_AirQuality_PM1.csv\n",
      "./output/IOT_AirQuality_PM10.csv\n",
      "./output/IOT_AirQuality_PM25.csv\n"
     ]
    }
   ],
   "source": [
    "## Save columns to csv in a custom order\n",
    "mandatory_column_list = [\"time\", \"lat\", \"long\"]\n",
    "data_column_list = [\"CO\", \"NO2\", \"O3\", \"Ox\", \"PM1\", \"PM10\", \"PM25\"]\n",
    "for data_column in data_column_list:\n",
    "    filepath = \"./output/\" + \"IOT_\" + \"AirQuality_\" + data_column + \".csv\"\n",
    "    print(filepath)\n",
    "    df.to_csv(filepath, columns = mandatory_column_list + [data_column], \n",
    "              index = False, na_rep = \"\", header = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
